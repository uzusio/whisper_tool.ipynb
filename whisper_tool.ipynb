{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uzusio/whisper_tool.ipynb/blob/main/whisper_tool.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77hp4SaVOw39"
      },
      "source": [
        "# 音声文字起こしツール for whisper\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## 概要\n",
        "OpenAIの[whisper](https://github.com/openai/whisper)を使用した音声文字起こしツールです。Google Colabの無料環境で動作し、簡単な初期設定だけで高精度な文字起こしが可能です。\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## 使い方\n",
        "\n",
        "1.   編集->ノートブックの設定->ハードウェア アクセラレータ から「T4 GPU」を選択してください\n",
        "\n",
        "2.   初期設定を入力してください\n",
        "     - **INPUT_MEDIA_PATH**:  \n",
        "       - `ファイルから読み込み`: 対象ファイルのパスを記入（例: `/content/hogehoge.mp3`）。  \n",
        "       - `URLから読み込み`: 動画や音声のURLを記入（例: `http://example.com/video`）。  \n",
        "     - **MODEL_TYPE**:  \n",
        "       文字起こしの精度を指定します。高精度な`large-v3`を推奨。  \n",
        "     - **srt_output**:  \n",
        "       字幕ファイル（.srt形式）の生成を有効化したい場合にチェックを入れてください。\n",
        "\n",
        "3. **セルを実行**\n",
        "   - 初期設定を入力後、以降のセルを上から順に実行してください。または「ランタイム」→「以降のセルを実行」でまとめて実行可能です。\n",
        "\n",
        "## リリースノート\n",
        "\n",
        "### 2024.11.19\n",
        "- UIを修正\n",
        "- 一部ライブラリのバージョンを固定\n",
        "- URLから動画をダウンロードできるように修正\n",
        "\n",
        "### 2024.3.5\n",
        "- Whisperを**faster-whisper**に切り替え、高速化。\n",
        "- Papago翻訳APIの仕様変更に伴い一時的に選択肢から削除。\n",
        "- マイク入力機能を削除。\n",
        "\n",
        "### 2023.1.13\n",
        "- マイクからの入力機能を追加。\n",
        "- Google翻訳およびPapago翻訳を追加。\n",
        "- Web上の動画をダウンロードする機能を追加。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_edxIOabN2AO"
      },
      "outputs": [],
      "source": [
        "#@title ## Googleドライブのマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "DCGevpCmrXQB"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "\n",
        "#@title ## 初期設定\n",
        "#@markdown ## 基本設定:\n",
        "#@markdown - メディアを入力（ファイルパスまたは動画ページのURLを入力）\n",
        "\n",
        "#@markdown (Tips)左サイドバーにファイルをドラッグ＆ドロップ → 右クリックで『パスをコピー』\n",
        "INPUT_MEDIA_PATH = \"例: /path/to/media.mp4 もしくは http://example.com/movieid\" #@param {type:\"string\"}\n",
        "DIR_PATH = None\n",
        "FILE_NAME = None\n",
        "\n",
        "# 自動判定するINPUT_TYPE\n",
        "if INPUT_MEDIA_PATH.startswith(\"http://\") or INPUT_MEDIA_PATH.startswith(\"https://\"):\n",
        "    INPUT_TYPE = \"URLから読み込み\"\n",
        "else:\n",
        "    INPUT_TYPE = \"ファイルから読み込み\"\n",
        "    DIR_PATH, FILE_NAME = os.path.split(INPUT_MEDIA_PATH)\n",
        "    # ファイルの存在チェック\n",
        "    if not os.path.exists(INPUT_MEDIA_PATH):\n",
        "        raise FileNotFoundError(f\"指定されたファイルが見つかりません: {INPUT_MEDIA_PATH}\")\n",
        "\n",
        "#@markdown - 利用するモデルサイズを選択\n",
        "MODEL_TYPE=\"large-v3\" #@param [\"tiny\", \"base\",\"small\",\"medium\",\"large\",\"large-v2\",\"large-v3\"] {type:\"string\"}\n",
        "\n",
        "#@markdown - 字幕ファイル(.srt)を出力したい場合下にチェック\n",
        "srt_output=True #@param {type: \"boolean\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "\n",
        "#@markdown ## 詳細設定:\n",
        "\n",
        "#@markdown - 認識言語（メディアの言語）を指定（\"auto\"だと自動判定されます）\n",
        "TRANS_FROM  = 'ja' #@param  [\"auto\",\"ja\",\"en\",\"ko\",\"zh-CN\",\"zh-TW\",\"es\",\"fr\",\"vi\",\"th\",\"id\"]\n",
        "\n",
        "#@markdown - 翻訳機能を有効にする場合下にチェック\n",
        "translate_option=False #@param {type: \"boolean\"}\n",
        "\n",
        "#@markdown - 翻訳エンジンを指定\n",
        "TRANSLATOR = 'GoogleTranslator' #@param [\"GoogleTranslator\", \"PapagoTranslator\"]\n",
        "\n",
        "#@markdown - 翻訳先言語を指定\n",
        "TRANS_TO  = 'ja' #@param  [\"ja\",\"en\",\"ko\",\"zh-CN\",\"zh-TW\",\"es\",\"fr\",\"vi\",\"th\",\"id\"]\n",
        "\n",
        "#@markdown - Webから動画ファイルも保存する\n",
        "save_video=False #@param {type: \"boolean\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OeCjEqh51ogd"
      },
      "outputs": [],
      "source": [
        "#@title ## 必要ライブラリのインストール\n",
        "# ctranslate2 のバージョンを固定してインストール\n",
        "!pip install ctranslate2==4.4.0\n",
        "\n",
        "!pip install faster_whisper==1.0.0\n",
        "!pip install srt\n",
        "!pip install deep-translator\n",
        "!pip install yt-dlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVa0NyZd7w0D"
      },
      "outputs": [],
      "source": [
        "#@title ## モデルのロード\n",
        "#import whisper\n",
        "from faster_whisper import WhisperModel\n",
        "\n",
        "# model = whisper.load_model(MODEL_TYPE)\n",
        "model = WhisperModel(MODEL_TYPE, device=\"cuda\", compute_type=\"float16\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "l5iwYvQ6q99Q"
      },
      "outputs": [],
      "source": [
        "#@title ## 文字起こし実行\n",
        "import subprocess\n",
        "\n",
        "# 入力ファイルパス\n",
        "file_path = INPUT_MEDIA_PATH\n",
        "\n",
        "if INPUT_TYPE == \"URLから読み込み\":\n",
        "    # ダウンロード形式オプション\n",
        "    format_option = \"mp4\" if save_video else \"mp3\"\n",
        "    yt_format = f\"{'-f mp4' if save_video else '-x --audio-format mp3'}\"\n",
        "\n",
        "    # yt-dlpでファイル名を取得\n",
        "    get_name_cmd = f\"yt-dlp --get-filename -o '%(title)s.%(ext)s' {yt_format} {INPUT_MEDIA_PATH}\"\n",
        "    file_name = subprocess.check_output(get_name_cmd, shell=True).decode(\"utf-8\").strip()\n",
        "\n",
        "    # ダウンロード\n",
        "    subprocess.run(f\"yt-dlp {yt_format} -o '{file_name}' {INPUT_MEDIA_PATH}\", shell=True)\n",
        "    file_path = f\"/content/{file_name}\"\n",
        "\n",
        "# Whisperで文字起こし\n",
        "segments, info = model.transcribe(\n",
        "    file_path,\n",
        "    beam_size=5,\n",
        "    vad_filter=True,\n",
        "    without_timestamps=True,\n",
        "    language=TRANS_FROM\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "2bgXU2Za5b_s"
      },
      "outputs": [],
      "source": [
        "import srt\n",
        "from datetime import timedelta\n",
        "from srt import Subtitle\n",
        "\n",
        "def translate_segments(segments, translator, target_lang, source_lang='auto'):\n",
        "    translated_segments = []\n",
        "\n",
        "    for segment in segments:\n",
        "        if translator == 'GoogleTranslator':\n",
        "            translated_text = GoogleTranslator(source=source_lang, target=target_lang).translate(segment.text)\n",
        "        # elif translator == 'PapagoTranslator':\n",
        "        #     translated_text = Translator(CLIENT_ID, SECRET_KEY).translate(text=segment.text, target=target_lang, source=source_lang).text\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown translator: {translator}\")\n",
        "\n",
        "        translated_segment = {\n",
        "            'text': translated_text,\n",
        "            'start': segment.start,\n",
        "            'end': segment.end\n",
        "        }\n",
        "        translated_segments.append(translated_segment)\n",
        "\n",
        "    return translated_segments\n",
        "\n",
        "\n",
        "def result2subs(segments, translate_option=False, translator=None, target_lang=None, source_lang='auto'):\n",
        "    if translate_option:\n",
        "        segments = translate_segments(segments, translator, target_lang, source_lang)\n",
        "    else:\n",
        "        # 翻訳オプションがOFFの場合、segmentsをそのままリストに変換\n",
        "        segments = [{'start': segment.start, 'end': segment.end, 'text': segment.text} for segment in segments]\n",
        "\n",
        "    subs = []\n",
        "\n",
        "    for i, segment in enumerate(segments):\n",
        "        start = segment['start']\n",
        "        end = segment['end']\n",
        "        text = segment['text']\n",
        "        sub = Subtitle(index=i+1, start=timedelta(seconds=start), end=timedelta(seconds=end), content=text)\n",
        "        subs.append(sub)\n",
        "\n",
        "    return subs\n",
        "\n",
        "# 字幕出力\n",
        "if srt_output:\n",
        "    if translate_option:\n",
        "        # 翻訳された字幕ファイルのみを出力\n",
        "        with open(f\"{file_path}_{TRANS_TO}.srt\", \"w\") as f:\n",
        "            f.write(srt.compose(result2subs(segments, translate_option=True, translator=TRANSLATOR, target_lang=TRANS_TO, source_lang=TRANS_FROM)))\n",
        "    else:\n",
        "        # 元の言語の字幕ファイルを出力\n",
        "        with open(f\"{file_path}.srt\", \"w\") as f:\n",
        "            f.write(srt.compose(result2subs(segments)))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "-5C70Tph4wnx"
      ],
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
