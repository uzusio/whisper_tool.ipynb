{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "77hp4SaVOw39"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/uzusio/whisper_tool.ipynb/blob/main/whisper_tool.ipynb)\n",
        "# 音声文字起こしツール for whisper\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## 概要\n",
        "OpenAIの[whisper](https://github.com/openai/whisper)を使用した音声文字起こしツールです。\n",
        "Google Colabの無料環境で利用可能です。\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## 使い方\n",
        "\n",
        "1.   編集->ノートブックの設定->ハードウェア アクセラレータ から「GPU」を選択してください（※初回以降は不要です）\n",
        "2.   Googleドライブに「whisper」というフォルダを作成してください（※初回以降は不要です）\n",
        "3.   一番目のセルを実行して、Googleドライブをマウントしてください\n",
        "4.   二番目のセルに設定を記述して、実行してください\n",
        "    1.   DIR_PATH: 文字起こしをする音声ファイルを配置するディレクトリです。文字起こしされたテキストファイルも同ディレクトリに出力されます。デフォルトではドライブ上の「whisper」フォルダになります。\n",
        "    2.   INPUT_FILE: 文字起こしする音声ファイルのファイル名です。 \n",
        "    3.   MODEL_TYPE： 文字起こしの精度を選びます。tiny<base<small<medium<largeの順に精度が上がります。※ダウンロードするモデルのファイルサイズも大きくなります。メモリエラーが起きたらモデルを１段階小さくしてください。\n",
        "    4.   srt_output: 字幕ファイル生成に対応しました。出力ファイルを字幕ファイル形式にしたい場合はチェックを入れてください。\n",
        "5.以降のセルを最後まで実行してください。ランタイム->以降のセルを実行でもOKです。\n",
        "\n",
        "### おまけ\n",
        "マイクからの入力機能も用意してみました。\n",
        "\n",
        "### 翻訳機能を追加（new!）\n",
        "Google翻訳とPapago翻訳を追加しました。DeepLも追加予定です。\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_edxIOabN2AO"
      },
      "outputs": [],
      "source": [
        "#@title ## Googleドライブのマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "DCGevpCmrXQB"
      },
      "outputs": [],
      "source": [
        "#@title ## 初期設定\n",
        "#@markdown ### 基本設定:\n",
        "#@markdown ・ファイルを配置するディレクトリを指定\n",
        "DIR_PATH=\"/content/drive/MyDrive/whisper\" #@param {type:\"string\"}\n",
        "#@markdown ・入力ファイル名\n",
        "INPUT_FILE=\"sample.mp4\" #@param {type:\"string\"}\n",
        "#@markdown ・利用するモデルサイズを選択\n",
        "MODEL_TYPE=\"large\" #@param [\"tiny\", \"base\",\"small\",\"medium\",\"large\"] {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "\n",
        "#@markdown ### 翻訳設定:\n",
        "\n",
        "#@markdown ・翻訳機能を有効にする場合下にチェック\n",
        "translate_option=True #@param {type: \"boolean\"}\n",
        "\n",
        "\n",
        "#@markdown ・翻訳エンジンを指定\n",
        "TRANSLATOR = 'GoogleTranslator' #@param [\"GoogleTranslator\", \"PapagoTranslator\"]\n",
        "\n",
        "#@markdown ・翻訳先言語を指定（翻訳元言語は自動判定されます）\n",
        "TRANS_TO  = 'ja' #@param  [\"ja\",\"en\",\"ko\",\"zh-CN\",\"zh-TW\",\"es\",\"fr\",\"vi\",\"th\",\"id\"]\n",
        "\n",
        "#@markdown ・「CLIENT_ID / SECRET_KEY」を指定（PapagoTranslatorを使用する場合に必要）\n",
        "CLIENT_ID = '' #@param {type:\"string\"}\n",
        "SECRET_KEY = '' #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "\n",
        "#@markdown ### 字幕ファイル設定（動画編集用）:\n",
        "#@markdown ・字幕ファイル(.srt)を出力したい場合下にチェック\n",
        "srt_output=True #@param {type: \"boolean\"}\n",
        "#@markdown ・字幕ファイル作成時、自動改行させる場合下にチェック\n",
        "line_option=True #@param {type: \"boolean\"}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OeCjEqh51ogd"
      },
      "outputs": [],
      "source": [
        "#@title ## 必要ライブラリのインストール\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!pip install srt\n",
        "!pip install deep-translator \n",
        "!pip install papago"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVa0NyZd7w0D",
        "outputId": "740b49ae-aef3-42f5-927d-71e7dd0cf2b5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████████████████████████████████| 2.87G/2.87G [00:36<00:00, 83.9MiB/s]\n"
          ]
        }
      ],
      "source": [
        "#@title ## モデルのロード\n",
        "import whisper\n",
        "\n",
        "model = whisper.load_model(MODEL_TYPE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "l5iwYvQ6q99Q"
      },
      "outputs": [],
      "source": [
        "#@title ## 文字起こし実行\n",
        "file_path = DIR_PATH + \"/\" + INPUT_FILE\n",
        "\n",
        "# 推論\n",
        "result = model.transcribe(file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "2bgXU2Za5b_s"
      },
      "outputs": [],
      "source": [
        "#@title ## 結果をGoogleドライブに保存\n",
        "from datetime import timedelta\n",
        "from srt import Subtitle\n",
        "import srt\n",
        "from deep_translator import GoogleTranslator\n",
        "from papago import Translator\n",
        "import copy\n",
        "\n",
        "# 翻訳実行\n",
        "if translate_option:\n",
        "  result_translated = copy.deepcopy(result)\n",
        "\n",
        "  if TRANSLATOR == 'GoogleTranslator':\n",
        "    for i,segment in enumerate(result[\"segments\"]):\n",
        "      result_translated['segments'][i]['text'] = GoogleTranslator(source='auto',target=TRANS_TO).translate(segment['text'])\n",
        "\n",
        "  elif TRANSLATOR == 'PapagoTranslator':\n",
        "    translator = Translator(CLIENT_ID, SECRET_KEY)\n",
        "    for i,segment in enumerate(result[\"segments\"]):\n",
        "      result_translated['segments'][i]['text'] = translator.translate(text=segment['text'], target=TRANS_TO).text\n",
        "\n",
        "\n",
        "def add_line(s):\n",
        "    new_s = s\n",
        "    s_count = len(s)\n",
        "    s_max_count = 15\n",
        "    if s_count >= s_max_count:\n",
        "        if (s_count - s_max_count) >= 3:\n",
        "            # 18文字以上であれば、15文字で改行する\n",
        "            new_s = s[:s_max_count] + \"\\n\" + s[s_max_count:]\n",
        " \n",
        "    return new_s\n",
        "\n",
        "def result2subs(result):\n",
        "  subs = []\n",
        "\n",
        "  for segment in result[\"segments\"]:\n",
        "    index = segment[\"id\"] + 1\n",
        "    start = segment[\"start\"]\n",
        "    end = segment[\"end\"]\n",
        "    text = add_line(segment[\"text\"]) if line_option else segment[\"text\"]\n",
        "    sub = Subtitle(index=1, start=timedelta(seconds=timedelta(seconds=start).seconds,\n",
        "                                            microseconds=timedelta(seconds=start).microseconds),\n",
        "                   end=timedelta(seconds=timedelta(seconds=end).seconds,\n",
        "                                 microseconds=timedelta(seconds=end).microseconds), content=text, proprietary='')\n",
        " \n",
        "    subs.append(sub)\n",
        "  return subs\n",
        "\n",
        "# 字幕出力\n",
        "if srt_output:\n",
        "  with open(f\"{file_path}.srt\", \"w\") as f:\n",
        "    f.write(srt.compose(result2subs(result)))\n",
        "  \n",
        "  if translate_option:\n",
        "    with open(f\"{file_path}_{TRANS_TO}.srt\", \"w\") as f:\n",
        "      f.write(srt.compose(result2subs(result_translated)))\n",
        "\n",
        "else:\n",
        "  with open(f\"{file_path}.txt\", \"w\") as f:\n",
        "    f.write(f\"▼ Transcription of {INPUT_FILE}\\n\")\n",
        "    for segment in result[\"segments\"]:\n",
        "      f.write(str(segment[\"id\"]) + \" \" + segment[\"text\"] + \"\\n\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6XT71CM1unn"
      },
      "outputs": [],
      "source": [
        "#@title ## 結果をテーブル表示で見る\n",
        "import pandas as pd\n",
        "pd.DataFrame(result[\"segments\"])[[\"start\", \"end\", \"text\"]]\n",
        "pd.DataFrame(result_translated[\"segments\"])[[\"start\", \"end\", \"text\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7S7Gny2Bdan0"
      },
      "source": [
        "# マイクから入力機能"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UaDf4kfrb91n"
      },
      "outputs": [],
      "source": [
        "#@title ## 必要ライブラリのインストール\n",
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FIpislkVYNc1"
      },
      "outputs": [],
      "source": [
        "#@title ## マイクから入力\n",
        "from transformers import pipeline\n",
        "import whisper\n",
        "import gradio as gr\n",
        "\n",
        "if not model:\n",
        "  model = whisper.load_model(MODEL_TYPE)\n",
        "\n",
        "p = pipeline(\"automatic-speech-recognition\")\n",
        "\n",
        "def transcribe(audio):\n",
        "    text = model.transcribe(audio)\n",
        "    return text\n",
        "\n",
        "gr.Interface(\n",
        "    fn=transcribe, \n",
        "    inputs=gr.Audio(source=\"microphone\", type=\"filepath\"), \n",
        "    outputs=\"text\").launch()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "7S7Gny2Bdan0"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
